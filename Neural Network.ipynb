{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Test = np.load('data/test_features.npy')\n",
    "Y_Test = np.load('data/test_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Valid = np.load('data/validation_features.npy')\n",
    "Y_Valid = np.load('data/validation_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train = np.stack((np.load('data/training_features1.npy'), np.load('data/training_features2.npy')), axis=0)\n",
    "Y_Train = np.stack((np.load('data/training_labels1.npy'), np.load('data/training_labels2.npy')), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train = X_Train.reshape((16000,209429))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209429,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Train = Y_Train.reshape((16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = np.load('index/test_index.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3220, 17774, 15275, ..., 12195, 12244,  7390])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_file = open(\"word_index_mapping.txt\",\"r\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index_map = {}\n",
    "content = map_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in content:\n",
    "    idx1 = line.find(',')\n",
    "    idx2 = line.find('\\n')\n",
    "    word = line[:idx1]\n",
    "    index = line[idx1+2:idx2-1]\n",
    "    word_index_map[word] = int(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word_map = {}\n",
    "for line in content:\n",
    "    idx1 = line.find(',')\n",
    "    idx2 = line.find('\\n')\n",
    "    word = line[:idx1]\n",
    "    index = line[idx1+2:idx2-1]\n",
    "    index_word_map[int(index)] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16821"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index_map['NOODLES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OF'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_word_map[38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 209429)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /nas/longleaf/home/mingzhi/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /nas/longleaf/home/mingzhi/.local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('models1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Pred = model.predict(X_Test, batch_size=4000)\n",
    "Y_Pred = Y_Pred>0.5\n",
    "#Y_Test = Y_Test.reshape((2000,1))\n",
    "#test_acc = (1.0*np.sum(Y_Pred==Y_Test))/(1.0*Y_Test.shape[0])\n",
    "#print('Test accuracy = '+str(test_acc)+' on '+str(Y_Test.shape[0])+' examples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.97 on 2000 examples.\n"
     ]
    }
   ],
   "source": [
    "Y_Test = Y_Test.reshape((2000,1))\n",
    "test_acc = (1.0*np.sum(Y_Pred==Y_Test))/(1.0*Y_Test.shape[0])\n",
    "print('Test accuracy = '+str(test_acc)+' on '+str(Y_Test.shape[0])+' examples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.logical_and(Y_Pred, Y_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive = np.logical_and(Y_Pred==True, Y_Test==False)\n",
    "false_negative = np.logical_and(Y_Pred==False, Y_Test==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(false_positive)\n",
    "#np.sum(false_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  24,   97,  184,  370,  408,  964, 1015, 1058, 1068, 1102, 1255,\n",
       "       1357, 1678, 1901, 1955])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(false_positive)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 108,  140,  151,  171,  212,  224,  238,  260,  281,  358,  391,\n",
       "        470,  599,  661,  705,  758,  801,  822,  859, 1020, 1031, 1235,\n",
       "       1272, 1303, 1317, 1338, 1343, 1348, 1366, 1390, 1395, 1455, 1535,\n",
       "       1543, 1595, 1604, 1695, 1722, 1736, 1794, 1802, 1858, 1891, 1938,\n",
       "       1968])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(false_negative)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = X_Test[np.nonzero(Y_Test)[0]]\n",
    "fake = X_Test[np.nonzero(Y_Test==False)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrequentWords(document, k, index_word_map):\n",
    "    ind = np.argpartition(document, -k)[-k:]\n",
    "    max_index = np.argmax(document)\n",
    "    words = []\n",
    "    for index in ind:\n",
    "        words.append(index_word_map[index])\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IS', 'TO', 'TRUMP', 'AND', 'BLACK']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = fake[0]\n",
    "getFrequentWords(document, 5, index_word_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AND', 'TO', 'THE', 'IN', 'OF']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = real[8]\n",
    "getFrequentWords(document, 5, index_word_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDocument(content, word_index_map):\n",
    "    document = [0 for i in range(209429)]\n",
    "    words = content.split(' ')\n",
    "    for i in range(len(words)):\n",
    "        words[i] = words[i].upper()\n",
    "        word = words[i]\n",
    "        if word[-1] in '!,.:;?()_=-+@#$%^&*\\'':\n",
    "            words[i] = word[:-1]\n",
    "        if words[i] in word_index_map:\n",
    "            document[word_index_map[words[i]]] += 1\n",
    "    return np.array(document).reshape((1,209429))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51925415]], dtype=float32)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = '''William Barr, Democrats Clash Over Robert Mueller’s Report By Sadie Gurman, Byron Tau and Kristina Peterson\n",
    "Updated May 1, 2019 7:50 p.m. ET\n",
    "\n",
    "WASHINGTON—Attorney General William Barr criticized Robert Mueller’s decision not to reach a conclusion about whether President Trump obstructed justice during a contentious hearing that laid bare a rift between him and the special counsel over the politically charged investigation.\n",
    "In his first congressional testimony since releasing a redacted version of Mr. Mueller’s 448-page report, Mr. Barr faced pointed criticism from Senate Democrats over his handling of the findings on Russian election interference in 2016.\n",
    "“If [Mr. Mueller] felt he shouldn’t go down a path of making a traditional prosecutive decision, then he shouldn’t have investigated,” Mr. Barr told the Senate Judiciary Committee Wednesday. “That was the time to pull up.”\n",
    "Meanwhile, the Justice Department late Wednesday told House Democrats that Mr. Barr wouldn’t appear at a Judiciary Committee hearing scheduled for Thursday over disagreements about the format of the appearance—and that an unredacted version of the Mueller report, which had been subpoenaed by the committee, wouldn’t be provided.\n",
    "SHARE YOUR THOUGHTS\n",
    "What do you think of Attorney General William Barr’s handling of the Mueller report? Join the conversation below.\n",
    "Rep. Jerrold Nadler (D., N.Y.), who chairs that committee, also threatened to hold the attorney general in contempt of Congress—a prelude to a court battle—for his continued refusal to turn over the unredacted Mueller report, a potentially dramatic escalation of tensions between congressional Democrats and the Trump administration.\n",
    "Wednesday’s Senate hearing offered a dramatic public display of the behind-the-scenes jockeying to give Mr. Mueller’s findings their proper airing. It came just after the Justice Department released a March 27 letter from Mr. Mueller to the attorney general, saying Mr. Barr’s early public portrayals of the report’s main conclusions failed to fully capture the work of the special counsel’s office.\n",
    "At the hearing, Mr. Barr called Mr. Mueller’s letter “a bit snitty” and suggested it was “written by one of his staff people.” Mr. Barr said he called Mr. Mueller the day after receiving it.\n",
    "“I said, ‘Bob, what’s with the letter? Why don’t you just pick up the phone and call me if there’s an issue?’ ” Mr. Barr said.\n",
    "Mr. Mueller “said his concern focused on his explanation of why he did not reach a conclusion on obstruction and he wanted more put out on that issue,” said Mr. Barr, recounting his conversation with Mr. Mueller. “He was very clear that he was not suggesting we had misrepresented his report.”\n",
    "Democrats didn’t agree on that characterization. Sen. Richard Blumenthal (D., Conn.) called the letter “an extraordinary act, a career prosecutor rebuking the attorney general of the United States.”\n",
    "Mr. Mueller’s letter was sent after the attorney general released his analysis of the investigation’s main conclusions in a four-page memo to Congress on March 24. Mr. Barr said he invited the special counsel to review the memo but that Mr. Mueller declined.\n",
    "When Mr. Mueller, driven largely by Justice Department policy against indicting a sitting president, declined in his report to make a recommendation about whether Mr. Trump obstructed justice during the investigation, Mr. Barr determined the special counsel’s evidence was insufficient to establish Mr. Trump committed a crime.\n",
    "Mr. Barr said Mr. Mueller’s reasoning on not pursuing an obstruction charge wasn’t immediately clear to him when the special counsel first told officials on March 5 that he wouldn’t be reaching a conclusion. The report detailed 10 episodes of potential obstruction of justice and made clear Mr. Mueller wasn’t exonerating the president.\n",
    "“We didn’t really get a clear understanding of the reasoning,” Mr. Barr said, adding that the 448-page report offered no concise explanation, either. “That’s one of the reasons why I didn’t want to put words in Bob Mueller’s mouth” before releasing the entire report.\n",
    "In the tense hearing that also highlighted partisan divisions on the Senate Judiciary Committee, Democrats pressed Mr. Barr on why he wasn’t more forthcoming about his disagreements with Mr. Mueller. Republicans on the panel repeatedly asked for information about whether the Federal Bureau of Investigation appropriately handled the early stages of the investigation, echoing the GOP president’s longstanding criticism of the Justice Department’s probe. \n",
    "Some Republicans asked about the status of a review Mr. Barr previously disclosed into what he termed “spying” on people affiliated with the Trump campaign. Among other allegations, the review is examining whether the FBI had appropriately obtained surveillance warrants against a former Trump foreign-policy adviser.\n",
    "“To the extent there was any overreach, I believe it was a few people in the upper echelons of the bureau and perhaps the department, but those people are no longer there,” Mr. Barr told Sen. Mike Lee (R., Utah).\n",
    "\n",
    "Multiple Democrats questioned whether Mr. Barr misled lawmakers at a House hearing last month, when he denied knowing of concerns by Mr. Mueller’s team about the attorney general’s four-page summary two days after receiving the report itself from the special counsel. At the time of that hearing, Mr. Barr had received two letters from Mr. Mueller and had had his phone conversation with him, all in connection with whether Mr. Barr had misrepresented the report. The Fight Over the Mueller Report Moves to Congress\n",
    "\n",
    "Congress is taking steps to see the unredacted Mueller report and the evidence that supports it. WSJ’s Siobhan Hughes looks at the political options that could play out in Congress. Photo Illustration: Adele Morgan\n",
    "“Why did you say you were not aware of concerns when weeks before your testimony Mr. Mueller had expressed concerns to you?” Sen. Patrick Leahy (D., Vt.) asked. Mr. Barr said he was accurately responding that he didn’t know what concerns he was being asked about.\n",
    "Mr. Mueller in his March 27 made it clear he preferred the report’s introduction and executive summaries—which his team had redacted so the material could be viewed by the public—be quickly released.\n",
    "But Mr. Barr testified Wednesday that, while he asked Mr. Mueller to make redactions in order to hasten the report’s release, he found when he received it on March 22 that the summaries still contained material that couldn’t be made public. He said he knew it would take weeks to make the edits.\n",
    "“I told Bob I wasn’t interested in putting out summaries,” he said. “I wanted to put out the whole report.”\n",
    "The hearing at times turned fiery. Asked by Sen. Kamala Harris (D., Calif.) if he would consult with career Justice Department officials about whether he would recuse himself from the more than a dozen investigations referred to other jurisdictions by the Mueller probe, Mr. Barr said he had no conflict of interest that would necessitate his recusal.\n",
    "\n",
    "“I think the American public has seen quite well that you are biased in this situation and you have not been objective,” said Ms. Harris, who is seeking the 2020 Democratic presidential nomination.\n",
    "In another exchange, after Sen. Mazie Hirono (D., Hawaii) explained why she voted against confirming Mr. Barr as attorney general, she said: “I expected you would try to protect the president and indeed you did,” before calling on Mr. Barr to resign.\n",
    "That drew a slap from Sen. Lindsey Graham of South Carolina, the panel’s GOP chairman.\n",
    "“Seven minutes and you’ve slandered this man from top to bottom,” Mr. Graham said.\n",
    "Earlier, Mr. Graham said the president couldn’t have obstructed justice if there was no underlying crime committed by Mr. Trump’s campaign associates. While the Mueller team found repeated contacts between the Trump campaign and Moscow-linked entities and that the Trump team expected it would benefit “from information stolen and released through Russian efforts,” the probe didn’t establish that members of the Trump campaign conspired with the Russian government.\n",
    "“Attempted obstruction of justice of a crime that never occurred seems to be the new standard around here, to me it doesn’t make any sense,” Mr. Graham said.\n",
    "Under the law, obstruction doesn’t require a successful effort. Nor does a prosecutor need to prove there was an underlying crime that a suspect was covering up.\n",
    "The House Judiciary panel in Thursday’s hearing wanted to have staff attorneys handle some of the questioning of the attorney general, but Mr. Barr balked.\n",
    "“The committee has the right to determine its own procedures,” Mr. Nadler said after getting the news that Mr. Barr wouldn’t appear. “The Congress cannot permit the executive branch, we cannot permit the administration, to dictate to Congress how we operate.”\n",
    "A Justice Department spokeswoman said that “Chairman Nadler’s insistence on having staff question the Attorney General, a Senate-confirmed Cabinet member, is inappropriate.”\n",
    "Write to Sadie Gurman at sadie.gurman@wsj.com, Byron Tau at byron.tau@wsj.com and Kristina Peterson at kristina.peterson@wsj.com\n",
    "Appeared in the May 2, 2019, print edition as 'Attorney General, Democrats Clash Over Mueller Report. \n",
    "'''\n",
    "document = createDocument(content, word_index_map)\n",
    "model.predict(document, batch_size=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    X_Test = np.load('data/test_features.npy')\n",
    "    Y_Test = np.load('data/test_labels.npy')\n",
    "    X_Valid = np.load('data/validation_features.npy')\n",
    "    Y_Valid = np.load('data/validation_labels.npy')\n",
    "    X_Train = np.stack((np.load('data/training_features1.npy'), np.load('data/training_features2.npy')), axis=0)\n",
    "    Y_Train = np.stack((np.load('data/training_labels1.npy'), np.load('data/training_labels2.npy')), axis=0)\n",
    "    Y_Test = Y_Test.reshape((2000,1))\n",
    "    Y_Valid = Y_Valid.reshape((2000,1))\n",
    "    X_Train = X_Train.reshape((16000,209429))\n",
    "    Y_Train = Y_Train.reshape((16000,1))\n",
    "    return X_Train, Y_Train, X_Valid, Y_Valid, X_Test, Y_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_size=(209429,)):\n",
    "    inputs = Input(input_size)\n",
    "    X1 = Dense(128, activation='relu')(inputs)\n",
    "    X2 = Dense(128, activation='relu')(X1)\n",
    "    X3 = Dense(64, activation='relu')(X2)\n",
    "    X4 = Dense(64, activation='relu')(X3)\n",
    "    X5 = Dense(32, activation='relu')(X4)\n",
    "    X6 = Dense(32, activation='relu')(X5)\n",
    "    X7 = Dense(16, activation='relu')(X6)\n",
    "    X8= Dense(16, activation='relu')(X7)\n",
    "    X9 = Dense(4, activation='relu')(X8)\n",
    "    X10 = Dense(4, activation='relu')(X9)\n",
    "    X11 = Dense(1, activation='relu')(X10)\n",
    "    outputs = Dense(1, activation='sigmoid')(X11)\n",
    "    \n",
    "    model = Model(input=inputs, output=outputs)\n",
    "    model.compile(optimizer=Adam(lr=1e-4), loss=\"binary_crossentropy\", metrics=['accuracy'], )\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/longleaf/home/mingzhi/.local/lib/python2.7/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 209429)            0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 128)               26807040  \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 26,839,999\n",
      "Trainable params: 26,839,999\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "  300/16000 [..............................] - ETA: 3:50 - loss: 0.6931 - acc: 0.4700"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-d5e58e7d7a31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_Valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/nas/longleaf/home/mingzhi/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/nas/longleaf/home/mingzhi/.local/lib/python2.7/site-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nas/longleaf/home/mingzhi/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nas/longleaf/home/mingzhi/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nas/longleaf/home/mingzhi/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_model = model()\n",
    "new_model.fit(X_Train, Y_Train, epochs=10, batch_size=300, validation_data=(X_Valid,Y_Valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.9605 on 2000 examples.\n"
     ]
    }
   ],
   "source": [
    "Y_Pred = new_model.predict(X_Test, batch_size=4000)\n",
    "Y_Pred = Y_Pred>0.5\n",
    "Y_Test = Y_Test.reshape((2000,1))\n",
    "test_acc = (1.0*np.sum(Y_Pred==Y_Test))/(1.0*Y_Test.shape[0])\n",
    "print('Test accuracy = '+str(test_acc)+' on '+str(Y_Test.shape[0])+' examples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "KK = Y_Pred == Y_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Y_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2000)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KK.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
